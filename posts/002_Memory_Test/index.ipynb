{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ceb26b6d-d77d-4a43-8a72-f9758596005e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Memory Test\"\n",
    "description: \"Testing how long an LLM can remeber my favorite color\"\n",
    "author: \"Logan Brassington\"\n",
    "date: \"2/3/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Memory\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58618eb-dd92-483b-a802-cf2083e61d6d",
   "metadata": {},
   "source": [
    "## Memory Test\n",
    "\n",
    "<img src=\"title.png\" width=\"50%\"/>\n",
    "\n",
    "***I am curious how long LLMs can hold onto user input.***\n",
    "\n",
    "To test this I will tell the LLM my favorite color (in this case dark green). Then I will tell it other information about myself like my age, favorite food, etc... before again asking the LLM what my favorite color is. I am going to increase the number of facts about myself to see where it will cap out and forget that my favorite color is dark green. I recognize that part of this constraint is the number of tokens I provide an LLM to remember (that is to say that a 100 word prompt in between would likely have more of an impact than a five word prompt), however for the purpose of this experiment I will only be counting based on the number of \"facts\" that I provide the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7e97a-f92e-411d-8c62-1608d7820af7",
   "metadata": {},
   "source": [
    "This relevant as when asking simple questions most LLMs can provide a response in the context of their trianing, but one of the more powerful use cases is when it can easily interact wiht user provided information. This is what makes it so powerful when drafting documents or code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4f8ce-0eb8-47b7-ab32-026a9efd5f34",
   "metadata": {},
   "source": [
    "### How does GPT response to the prompt?\n",
    "\n",
    "**GPT4o - 3 Facts**\n",
    "\n",
    "<img src=\"img1.png\" width=\"50%\"/>\n",
    "\n",
    "GPT 4o correctly remembered that my favorite color was dark green after 3 facts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62a4b3-9f0b-4e2d-9b32-cf19be36d518",
   "metadata": {},
   "source": [
    "**GPT4o - 6 Facts**\n",
    "\n",
    "<img src=\"img1.png\" width=\"50%\"/>\n",
    "\n",
    "GPT 4o correctly remembered that my favorite color was dark green after 3 facts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda418a8-0acb-4536-87cc-fc3d67e14040",
   "metadata": {},
   "source": [
    "**GPT4o - 12 Facts**\n",
    "\n",
    "<img src=\"img3.png\" width=\"50%\"/>\n",
    "\n",
    "GPT 4o correctly remembered that my favorite color was dark green after 12 facts. (Note that this is a different chat despite the image continuing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4318c19-7052-4c96-b488-efd94ea4c74e",
   "metadata": {},
   "source": [
    "**GPT4o - 50 Facts**\n",
    "\n",
    "<img src=\"img4.png\" width=\"50%\"/>\n",
    "\n",
    "GPT 4o did not remember my favorite color after 50 facts. (Note that this is a different chat despite the image continuing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1c718-1ed5-4aa2-8df9-d6d4d4010f6c",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "It is worth noting that initially GPT did a great job at remembering this simple fact after preventing it with a few number of facts, but as that number grew, at some point it was not able to remeber the intial piece of information. My understanding is that this is because there is memory that GPT uses that will run out at a certain point. I would also imagine (as noted above) that the length of the input and information GPT has to remember would impact how many messages can pass while GPT retains this information - which at a certain point is system design more than anything else.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ee64f-643d-498e-af25-537efde03de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
