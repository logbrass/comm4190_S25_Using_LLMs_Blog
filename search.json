[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "Memory Test\n\n\n\n\n\n\nLLMs\n\n\nMemory\n\n\n\nTesting how long an LLM can remeber my favorite color\n\n\n\n\n\nFeb 3, 2025\n\n\nLogan Brassington\n\n\n\n\n\n\n\n\n\n\n\n\nTESTING AGAIN\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nJan 29, 2025\n\n\nLOGAN BRASSINGTON\n\n\n\n\n\n\n\n\n\n\n\n\nCan ChatGPT Replace a Counsler?\n\n\n\n\n\n\nLLMs\n\n\nJob Market\n\n\n\nExploration into LLM for job replacement\n\n\n\n\n\nFeb 18, 2024\n\n\nLogan Brassington\n\n\n\n\n\n\n\n\n\n\n\n\nLLM‚Äôs Drawing Words\n\n\n\n\n\n\nLLMs\n\n\nArt\n\n\n\nExploration of \n\n\n\n\n\nFeb 10, 2024\n\n\nLogan Brassington\n\n\n\n\n\n\n\n\n\n\n\n\nHumanity‚Äôs Last Exam Overview\n\n\n\n\n\n\nLLMs\n\n\nBenchmarking\n\n\n\nAn overview of the HLE Benchmark and how GPT 4o does on a few questions\n\n\n\n\n\nFeb 6, 2024\n\n\nLogan Brassington\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/002_Memory_Test/index.html",
    "href": "posts/002_Memory_Test/index.html",
    "title": "Memory Test",
    "section": "",
    "text": "I am curious how long LLMs can hold onto user input.\nTo test this I will tell the LLM my favorite color (in this case dark green). Then I will tell it other information about myself like my age, favorite food, etc‚Ä¶ before again asking the LLM what my favorite color is. I am going to increase the number of facts about myself to see where it will cap out and forget that my favorite color is dark green. I recognize that part of this constraint is the number of tokens I provide an LLM to remember (that is to say that a 100 word prompt in between would likely have more of an impact than a five word prompt), however for the purpose of this experiment I will only be counting based on the number of ‚Äúfacts‚Äù that I provide the LLM.\nThis relevant as when asking simple questions most LLMs can provide a response in the context of their trianing, but one of the more powerful use cases is when it can easily interact wiht user provided information. This is what makes it so powerful when drafting documents or code.\n\n\nGPT4o - 3 Facts\n\nGPT 4o correctly remembered that my favorite color was dark green after 3 facts.\nGPT4o - 6 Facts\n\nGPT 4o correctly remembered that my favorite color was dark green after 3 facts.\nGPT4o - 12 Facts\n\nGPT 4o correctly remembered that my favorite color was dark green after 12 facts. (Note that this is a different chat despite the image continuing).\nGPT4o - 50 Facts\n\nGPT 4o did not remember my favorite color after 50 facts. (Note that this is a different chat despite the image continuing)."
  },
  {
    "objectID": "posts/002_Memory_Test/index.html#memory-test",
    "href": "posts/002_Memory_Test/index.html#memory-test",
    "title": "Memory Test",
    "section": "",
    "text": "I am curious how long LLMs can hold onto user input.\nTo test this I will tell the LLM my favorite color (in this case dark green). Then I will tell it other information about myself like my age, favorite food, etc‚Ä¶ before again asking the LLM what my favorite color is. I am going to increase the number of facts about myself to see where it will cap out and forget that my favorite color is dark green. I recognize that part of this constraint is the number of tokens I provide an LLM to remember (that is to say that a 100 word prompt in between would likely have more of an impact than a five word prompt), however for the purpose of this experiment I will only be counting based on the number of ‚Äúfacts‚Äù that I provide the LLM.\nThis relevant as when asking simple questions most LLMs can provide a response in the context of their trianing, but one of the more powerful use cases is when it can easily interact wiht user provided information. This is what makes it so powerful when drafting documents or code.\n\n\nGPT4o - 3 Facts\n\nGPT 4o correctly remembered that my favorite color was dark green after 3 facts.\nGPT4o - 6 Facts\n\nGPT 4o correctly remembered that my favorite color was dark green after 3 facts.\nGPT4o - 12 Facts\n\nGPT 4o correctly remembered that my favorite color was dark green after 12 facts. (Note that this is a different chat despite the image continuing).\nGPT4o - 50 Facts\n\nGPT 4o did not remember my favorite color after 50 facts. (Note that this is a different chat despite the image continuing)."
  },
  {
    "objectID": "posts/002_Memory_Test/index.html#takeaways",
    "href": "posts/002_Memory_Test/index.html#takeaways",
    "title": "Memory Test",
    "section": "Takeaways",
    "text": "Takeaways\nIt is worth noting that initially GPT did a great job at remembering this simple fact after preventing it with a few number of facts, but as that number grew, at some point it was not able to remeber the intial piece of information. My understanding is that this is because there is memory that GPT uses that will run out at a certain point. I would also imagine (as noted above) that the length of the input and information GPT has to remember would impact how many messages can pass while GPT retains this information - which at a certain point is system design more than anything else."
  },
  {
    "objectID": "posts/004_LLM_Art/index.html",
    "href": "posts/004_LLM_Art/index.html",
    "title": "LLM‚Äôs Drawing Words",
    "section": "",
    "text": "One of the areas that I have noticed LLMs to be particularly weak in is specific image generation. These diffusion models perform great when given an abstract task like ‚Äúdraw a cat in the middle of space‚Äù:\n\nWe can clearly see that it creatively comes up with a cat (an American cat at that) in vivid detail. We could specify more instruction, like a different art form or change a detail of the cat. However this is where LLMs perfomance in image generation seem to drop off. When tasked with creating more finite images that are seemingly simple - I have found that LLMs tend to create blurry images with mistakes. We can explore this poor perfomance by asking Dalle to generate images containing words that are increasingly complex."
  },
  {
    "objectID": "posts/004_LLM_Art/index.html#image-generation",
    "href": "posts/004_LLM_Art/index.html#image-generation",
    "title": "LLM‚Äôs Drawing Words",
    "section": "",
    "text": "One of the areas that I have noticed LLMs to be particularly weak in is specific image generation. These diffusion models perform great when given an abstract task like ‚Äúdraw a cat in the middle of space‚Äù:\n\nWe can clearly see that it creatively comes up with a cat (an American cat at that) in vivid detail. We could specify more instruction, like a different art form or change a detail of the cat. However this is where LLMs perfomance in image generation seem to drop off. When tasked with creating more finite images that are seemingly simple - I have found that LLMs tend to create blurry images with mistakes. We can explore this poor perfomance by asking Dalle to generate images containing words that are increasingly complex."
  },
  {
    "objectID": "posts/004_LLM_Art/index.html#generate-an-image-with-the-word-cat",
    "href": "posts/004_LLM_Art/index.html#generate-an-image-with-the-word-cat",
    "title": "LLM‚Äôs Drawing Words",
    "section": "‚ÄúGenerate an image with the word CAT‚Äù",
    "text": "‚ÄúGenerate an image with the word CAT‚Äù\n\nWhile this is techincally correct, it seems to have jumped to doing an artistic rendering of the word CAT. We can try to specify things a bit more to recieve the desired output."
  },
  {
    "objectID": "posts/004_LLM_Art/index.html#generate-a-plain-image-with-the-word-cat-the-word-should-be-black-with-a-simple-white-background",
    "href": "posts/004_LLM_Art/index.html#generate-a-plain-image-with-the-word-cat-the-word-should-be-black-with-a-simple-white-background",
    "title": "LLM‚Äôs Drawing Words",
    "section": "‚ÄúGenerate a plain image with the word CAT (the word should be black with a simple white background)‚Äù",
    "text": "‚ÄúGenerate a plain image with the word CAT (the word should be black with a simple white background)‚Äù\n\nHere we were able to obtain the black word - but the rest of the smaller letters beneath the word CAT look like an eye exam. It is also important to note that some of those smaller letters seem to be smudged or cut off. At this point, maybe if we give some more specification around what we want, we can get the proper result."
  },
  {
    "objectID": "posts/004_LLM_Art/index.html#generate-a-plain-image-with-the-word-cat-the-word-should-be-black-with-a-simple-white-background.-there-should-be-no-other-letters-in-the-image.-the-goal-is-to-mimic-a-black-piece-of-paper-only-the-word-cat.-you-are-not-an-artist.",
    "href": "posts/004_LLM_Art/index.html#generate-a-plain-image-with-the-word-cat-the-word-should-be-black-with-a-simple-white-background.-there-should-be-no-other-letters-in-the-image.-the-goal-is-to-mimic-a-black-piece-of-paper-only-the-word-cat.-you-are-not-an-artist.",
    "title": "LLM‚Äôs Drawing Words",
    "section": "‚ÄúGenerate a plain image with the word CAT (the word should be black with a simple white background). There should be no other letters in the image. The goal is to mimic a black piece of paper only the word CAT. You are not an artist.‚Äù",
    "text": "‚ÄúGenerate a plain image with the word CAT (the word should be black with a simple white background). There should be no other letters in the image. The goal is to mimic a black piece of paper only the word CAT. You are not an artist.‚Äù\n\nThis time around we can see that this is far closer to the result that we want, but it isn‚Äôt exactly right. There is an odd grey boarder that was not requested. At this point - maybe we should ask Chat GPT 4o what the best image generation prompt is:\n\nLet‚Äôs try it:"
  },
  {
    "objectID": "posts/004_LLM_Art/index.html#a-plain-white-background-with-the-word-cat-in-bold-black-text-centered.-no-other-elements-decorations-or-details.",
    "href": "posts/004_LLM_Art/index.html#a-plain-white-background-with-the-word-cat-in-bold-black-text-centered.-no-other-elements-decorations-or-details.",
    "title": "LLM‚Äôs Drawing Words",
    "section": "‚ÄúA plain white background with the word ‚ÄòCAT‚Äô in bold black text, centered. No other elements, decorations, or details.‚Äù",
    "text": "‚ÄúA plain white background with the word ‚ÄòCAT‚Äô in bold black text, centered. No other elements, decorations, or details.‚Äù\n\nThis did the trick! It seems that the exact prompting with Dalle matters the most. At this point it begs more of a UI question with AI that if text to image if meant to be widely accisble, how can an image generation interface be better suited for a layman user? Maybe it would be better to provide users with a more guided experience, such as preset templates for common requests or a more interactive prompt refinement system - instead of requiring users to perfectly craft a text prompt.\nIn the future when trying to generate an image, it might be best to just ask an LLM what the best way to do this is!"
  },
  {
    "objectID": "posts/005_ChatGPT_Emotional_Response/index.html",
    "href": "posts/005_ChatGPT_Emotional_Response/index.html",
    "title": "Can ChatGPT Replace a Counsler?",
    "section": "",
    "text": "One of the fears that many have is that AI will take their job. They fear that one day we will wake up and GenAI will be able to take the job of every Software Engineer, Accountant, Business Analyst - anything with code of a spreadsheet. However some feel that they will not be touched at all by the AI revolution - Postmen, Plumbers, Construction workers - anyone who works in the ‚Äúreal world‚Äù. There are others who have confidence but should perhaps be less sure - like Psychologists or Counslers. Today I will explore how effective Chat GPT 4o is at when I share that my mental health is not great (something that I will note is purely for expirmentation purposes.\n\n\nBelow you will see that I: - Share my inital thoughts and feelings - Respond to any questions / provide more detail if needed - Then ask what I should do going forward\nI am curious if ChatGPT will try to tackle the issue head on on or if GPT will recomend professional (non-AI) help at any point."
  },
  {
    "objectID": "posts/005_ChatGPT_Emotional_Response/index.html#which-jobs-will-llms-replace",
    "href": "posts/005_ChatGPT_Emotional_Response/index.html#which-jobs-will-llms-replace",
    "title": "Can ChatGPT Replace a Counsler?",
    "section": "",
    "text": "One of the fears that many have is that AI will take their job. They fear that one day we will wake up and GenAI will be able to take the job of every Software Engineer, Accountant, Business Analyst - anything with code of a spreadsheet. However some feel that they will not be touched at all by the AI revolution - Postmen, Plumbers, Construction workers - anyone who works in the ‚Äúreal world‚Äù. There are others who have confidence but should perhaps be less sure - like Psychologists or Counslers. Today I will explore how effective Chat GPT 4o is at when I share that my mental health is not great (something that I will note is purely for expirmentation purposes.\n\n\nBelow you will see that I: - Share my inital thoughts and feelings - Respond to any questions / provide more detail if needed - Then ask what I should do going forward\nI am curious if ChatGPT will try to tackle the issue head on on or if GPT will recomend professional (non-AI) help at any point."
  },
  {
    "objectID": "posts/005_ChatGPT_Emotional_Response/index.html#conversation",
    "href": "posts/005_ChatGPT_Emotional_Response/index.html#conversation",
    "title": "Can ChatGPT Replace a Counsler?",
    "section": "Conversation",
    "text": "Conversation\nYou said: Hi! I am not feeling so great today.\nChatGPT said: Hey Logan, I‚Äôm sorry to hear that. Rough day, or just not feeling 100%? Want to talk about it, or would you rather just chat about something fun to take your mind off things?\nYou said: I‚Äôll talk about it a bit - I just had a really tough day, there was so much going on between classes, work, and dealing with others.\nChatGPT said: That sounds really overwhelming, Logan. Juggling classes, work, and dealing with people all at once can be exhausting. I can imagine it feels like there‚Äôs barely any room to breathe.\nWas there something specific that made today extra tough, or was it just everything piling up at once?\nYou said: I think it was just everything piling up at once.\nChatGPT said: Yeah, that makes sense. When everything stacks up like that, even small things can feel way heavier. It‚Äôs frustrating when there‚Äôs no clear break to catch your breath.\nDo you have anything coming up‚Äîlike a free evening, a small break, or even just a quiet moment‚Äîwhere you can take a step back and reset? Or do you feel like the pressure‚Äôs still going to keep building?\nYou said: Yeah I will hopefully have a break during the weekend - then maybe something fun will happen.\nChatGPT said: That‚Äôs good to hear‚Äîyou definitely deserve a break. Maybe you can plan something small to look forward to, even if it‚Äôs just a chill night, watching a movie, or doing something you enjoy.\nIf you want, we can brainstorm something fun to do this weekend, or I can just be here to chat and take your mind off things for a bit. Whatever helps!\nYou said: What ideas do you have - how can avoid this in the future?\nChatGPT said: For the weekend, it depends on what kind of break you need. Here are a few ideas based on different ways you might want to recharge:\n\nLow-effort relaxation: Watch a movie, play a casual game, or go for a walk somewhere nice. Something that doesn‚Äôt require much thinking but lets you reset.\nSocial but stress-free: Hang out with friends in a way that doesn‚Äôt add pressure‚Äîmaybe a board game night, getting food, or just vibing somewhere.\nSomething new/exciting: If you want to shake things up, you could try a new activity‚Äîan escape room, a new restaurant, or a random event happening near you.\nPhysical reset: If you feel burnt out, something like going to the gym, playing a sport, or even just stretching and getting fresh air could help.\n\nHow to Avoid This in the Future It‚Äôs tough, but here are a few ways to keep things from piling up too much:\n\nPreemptively block off time for breaks ‚Äì Even if you‚Äôre super busy, scheduling small breaks (even 10-15 mins) can stop things from spiraling.\nSet ‚Äòoff-limits‚Äô hours ‚Äì A time at night where you stop working and let your mind rest. No school, no work, just chill time. Prioritize what actually matters ‚Äì When everything feels urgent, it‚Äôs easy to stress over things that don‚Äôt deserve it. If you can, let go of the smaller stuff.\nDelegate or push back where possible ‚Äì If you‚Äôre taking on too much at once, is there anything you can shift around or ask for help with?\nCheck in with yourself sooner ‚Äì If you feel stress building mid-week, take a step back instead of letting it pile up to breaking point.\nWhat do you think? Do any of these feel doable, or is there something specific that usually pushes you over the edge?\n\nYou said: Yes this all helps! Thank you so much!\nChatGPT said: I‚Äôm really glad to hear that it helped! It sounds like you‚Äôre finding some good ways to take a breather, and I hope your weekend break brings you the recharge you need. Remember, it‚Äôs totally okay to prioritize yourself when things get overwhelming. If you ever want to chat more or brainstorm additional ideas, I‚Äôm here for you. Take care!\n\nTakeways\nOverall ChatGPT did a solid job at providing something to talk to and recenter my attention. I did find it interesting that it kept throwing things back onto me to push the conversation forward - I had to prompt it to give specific advice. FWIW - I think that LLMS perform better as you give more information - maybe I should have selected a more specific situation.\nI found it interesting that ChatGPT did not recomend professional help at any point. I think that there is great promise for the ChatGPT to be a mental health first responder of sorts - especially as LLMs are applied to voices / humanoids to be more personal."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "TESTING AGAIN",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "TESTING AGAIN",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/001_testing_again/index.html",
    "href": "posts/001_testing_again/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/001_testing_again/index.html#a-visualization-problem-for-llms",
    "href": "posts/001_testing_again/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/003_Human_Test/index.html",
    "href": "posts/003_Human_Test/index.html",
    "title": "Humanity‚Äôs Last Exam Overview",
    "section": "",
    "text": "Benchmarking for LLMs is like standarardized testing to compare models. By having models do the same set of tasks or answer the same set of questions, we can see how they perform against eachother. The idea of benchmarking is placing a relative place for compaision and exists in almost all disciplines.\nThe benchmark that we will look at today, Humanity‚Äôs Last Exam (HLE), is an exam comprised of 3,000 difficult out of context questions from a variety of fields including, mathematics, humanities, and the natural sciences. The exam is multimodel - with some questions having images and others being purely text-based.\nFor context of the difficult of the exam see the below image of various model‚Äôs perfomance on the HLE benchmark:\n\n\n\nWe can see that no model is performing well on the bench mark (with the max being a 13 percent accuracy). Knowing this we can test some of these sample questions on GPT to see how it performs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe should note that the answers are not provided to these questions (as this would potentially leak them to be trained by an LLM) so for now we will have to use guess ourselves if this is infact the correct response (likely not as we can see above). This benchmark will serve as a good indicator for the progress of LLMs. That is to say that if a model is able to perform well on such an assessment that it has been exposed to such a wide range of material that it is able to answer even the most obscurley difficult domain specific questions correctly. For some, HLE serves as the final indicator of AGI, while for others it is just another in a long line of benchmarks."
  },
  {
    "objectID": "posts/003_Human_Test/index.html#benchmarking",
    "href": "posts/003_Human_Test/index.html#benchmarking",
    "title": "Humanity‚Äôs Last Exam Overview",
    "section": "",
    "text": "Benchmarking for LLMs is like standarardized testing to compare models. By having models do the same set of tasks or answer the same set of questions, we can see how they perform against eachother. The idea of benchmarking is placing a relative place for compaision and exists in almost all disciplines.\nThe benchmark that we will look at today, Humanity‚Äôs Last Exam (HLE), is an exam comprised of 3,000 difficult out of context questions from a variety of fields including, mathematics, humanities, and the natural sciences. The exam is multimodel - with some questions having images and others being purely text-based.\nFor context of the difficult of the exam see the below image of various model‚Äôs perfomance on the HLE benchmark:\n\n\n\nWe can see that no model is performing well on the bench mark (with the max being a 13 percent accuracy). Knowing this we can test some of these sample questions on GPT to see how it performs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe should note that the answers are not provided to these questions (as this would potentially leak them to be trained by an LLM) so for now we will have to use guess ourselves if this is infact the correct response (likely not as we can see above). This benchmark will serve as a good indicator for the progress of LLMs. That is to say that if a model is able to perform well on such an assessment that it has been exposed to such a wide range of material that it is able to answer even the most obscurley difficult domain specific questions correctly. For some, HLE serves as the final indicator of AGI, while for others it is just another in a long line of benchmarks."
  },
  {
    "objectID": "Untitled.html",
    "href": "Untitled.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "def answer(text):\n    words = text.strip().split()\n    parts = [ w[-1] for w in words ]\n    return ''.join(parts)\n\n\nanswer('DOG CATTT BANANA')\n\n'GTA'"
  }
]